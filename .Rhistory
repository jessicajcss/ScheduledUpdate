rm(meteo_colombo)
ultima_data <- last_meteo_colombo |>
dplyr::mutate(date = as.Date(date)) |>
dplyr::arrange(date) |>
tail(1) |>
dplyr::select(date)
# Exampledate# Example usage ----
start_date <- ultima_data$date #"2023-06-01" # m√°ximo de um ano!!
end_date <- Sys.Date()+1
station_code <- "B806"
seu_token <- Sys.getenv("INMET_TOKEN")
data <- download_data(start_date, end_date, station_code)
df <- convert_to_df(data)
# Print the first few rows
print(head(df))
meteo_colombo <- df |>
dplyr::mutate(data = as.Date(DT_MEDICAO),
time = sub("00", "", HR_MEDICAO),# sub("(\\d+)(\\d{2})", "\\1:\\2", Hora.Medicao))
date = lubridate::ymd_hms(paste0(data," ", time, ":00:00")),
uv = NA) |>
dplyr::select(DC_NOME, date, TEM_INS, VEN_VEL, VEN_DIR, CHUVA, UMD_INS, RAD_GLO, PRE_INS, uv)
colnames(meteo_colombo) <- c('Cidade', 'date', 'temp', 'ws', 'wd', 'prec', 'umid', 'rad', 'press', 'uv')
meteo_colombo <- meteo_colombo |>
dplyr::mutate(date = lubridate::with_tz(date, tz = "America/Chicago")) |>
dplyr::mutate(date = lubridate::force_tz(date, tz = "America/Sao_Paulo")) |>
dplyr::mutate(Cidade = "Colombo",
across(c(temp, ws, wd, prec, umid, rad, press, uv), as.numeric))
meteo_colombo <- rbind(meteo_colombo, last_meteo_colombo) |>
dplyr::arrange(date) |>
unique() |>
subset(!is.na(temp))
save(meteo_colombo, file = "./data/meteo_colombo.Rda")
conflicted::conflict_scout(
source("./R/00-access-INMET_API-data.R")
)
# Function to get JWT token (only when needed)
get_jwt_token <- function() {
if (exists("global_jwt_token") && !is.null(global_jwt_token)) {
return(global_jwt_token)
}
plugfield_auth <- Sys.getenv("PLUG_AUTH")  # Simula a requisi√ß√£o do token, new Auth using POSTMAN
global_jwt_token <<- plugfield_auth  # Save token globally
return(global_jwt_token)
}
jwt_token <- NULL  # Vari√°vel global
get_jwt_token <- function() {
if (!is.null(jwt_token)) {
return(jwt_token)
}
plugfield_auth <- Sys.getenv("PLUG_AUTH")  # Simula requisi√ß√£o
assign("jwt_token", plugfield_auth, envir = .GlobalEnv)  # Salva na mem√≥ria
return(plugfield_auth)
}
# Function to fetch data (optimizing request frequency)
fetch_large_data <- function(device_id, start_date, end_date) {
max_days <- 30  # API limit
all_data <- list()  # Store all chunks
current_start <- start_date
plugfield_api <- Sys.getenv("PLUG_API")
jwt_token <- get_jwt_token()  # Fetch token once
while (current_start < end_date) {
current_end <- min(current_start + lubridate::days(max_days), end_date)  # 30-day chunks
# Format API request
begin_date <- format(current_start, "%d/%m/%Y+%H")
end_date_formatted <- format(current_end, "%d/%m/%Y+%H")
url <- paste0("https://prod-api.plugfield.com.br/data/hourly?device=", device_id,
"&begin=", begin_date,
"&end=", end_date_formatted)
# Debugging: Print the URL to check for correctness
print(paste("Requesting URL:", url))
headers <- httr::add_headers(
'accept' = 'application/json',
'x-api-key' = plugfield_api,
'Authorization' = jwt_token
)
# Request data
res <- httr::GET(url, headers)
if (httr::status_code(res) == 403) {
message("Token expired, requesting new token...")
jwt_token <<- get_jwt_token()  # Refresh token
headers <- httr::add_headers(
'accept' = 'application/json',
'x-api-key' = plugfield_api,
'Authorization' = jwt_token
)
res <- httr::GET(url, headers)  # Retry request
}
# Process response
if (httr::status_code(res) == 200) {
json_data <- jsonlite::fromJSON(httr::content(res, "text", encoding = "UTF-8"), flatten = TRUE)
df <- as.data.frame(json_data)
all_data <- append(all_data, list(df))
} else {
message("Error:", httr::status_code(res))
}
# Move to next period
current_start <- current_end + lubridate::seconds(1)
Sys.sleep(0.2)  # Avoid excessive requests
}
return(dplyr::bind_rows(all_data))
}
load(file = "./data/meteo/meteo_rbs.Rda")
last_meteo_rbs <- meteo_rbs |>
dplyr::mutate(date = lubridate::force_tz(date, tz = "America/Sao_Paulo"))
rm(meteo_rbs)
ultima_data <- last_meteo_rbs |>
dplyr::mutate(date = lubridate::as_datetime(date, tz = "America/Sao_Paulo")) |>
dplyr::arrange(date) |>
tail(1) |>
dplyr::select(date)
#########################################################################
start_date <- ultima_data$date #"2023-06-01" # m√°ximo de um ano!!
#start_date <- ymd_hms("2025-01-01 00:00:00")
end_date <- Sys.time() #"26/02/2025 00:00:00"  # End period (more than 30 days)
# DADOS ESCOLA
device_id <- 3184
df_escola <- fetch_large_data(device_id, start_date, end_date)
#########################################################################
start_date <- ultima_data$date #"2023-06-01" # m√°ximo de um ano!!
load(file = "./data/meteo/meteo_rbs.Rda")
View(meteo_rbs)
last_meteo_rbs <- meteo_rbs |>
dplyr::mutate(date = lubridate::with_tz(date, tz = "America/Sao_Paulo")) |>
subset(date > lubridate::as_datetime("2025-03-10 00:00:00"))
last_meteo_rbs <- meteo_rbs |>
dplyr::mutate(date = lubridate::with_tz(date, tz = "America/Sao_Paulo")) |>
subset(date < lubridate::as_datetime("2025-03-10 00:00:00"))
rm(meteo_rbs)
ultima_data <- last_meteo_rbs |>
dplyr::mutate(date = lubridate::as_datetime(date, tz = "America/Sao_Paulo")) |>
dplyr::arrange(date) |>
tail(1) |>
dplyr::select(date)
#########################################################################
start_date <- ultima_data$date #"2023-06-01" # m√°ximo de um ano!!
#start_date <- ymd_hms("2025-01-01 00:00:00")
end_date <- Sys.time() #"26/02/2025 00:00:00"  # End period (more than 30 days)
# DADOS ESCOLA
device_id <- 3184
df_escola <- fetch_large_data(device_id, start_date, end_date)
# DADOS DEFESA CIVIL
device_id <- 3118
df_defesacivil <- fetch_large_data(device_id, start_date, end_date)
# joining all data from rio branco do sul
df <- rbind(df_escola, df_defesacivil)
df <- df |>
dplyr::mutate(across(where(is.list), ~ purrr::map_chr(., ~ if (length(.) == 0) NA else paste(., collapse = ",")))) |>  # Flatten lists
dplyr::select(where(~ !all(is.na(.))) &  where(~ !all(. == "NULL", na.rm = TRUE)))  # Remove all-NA or all-NULL columns [where(~ !all(. == 0, na.rm = TRUE)) &]
View(df)
# fix timestamp format
df[[40]] <- lubridate::ymd_hms(df[[38]], tz = "America/Sao_Paulo")
# joining all data from rio branco do sul
df <- rbind(df_escola, df_defesacivil)
df <- df |>
dplyr::mutate(across(where(is.list), ~ purrr::map_chr(., ~ if (length(.) == 0) NA else paste(., collapse = ",")))) |>  # Flatten lists
dplyr::select(where(~ !all(is.na(.))) &  where(~ !all(. == "NULL", na.rm = TRUE)))  # Remove all-NA or all-NULL columns [where(~ !all(. == 0, na.rm = TRUE)) &]
# fix timestamp format
df[[40]] <- lubridate::ymd_hms(df[[38]])
# Preparando periodo sem dados na esta√ß√£o defesa civil [NA] para substituir por dados escola
meteo_rbs_dc <- df |>
subset(deviceId == 3118)
meteo_rbs_esc <- df |>
subset(deviceId == 3184)
res <- meteo_rbs_dc[is.na(meteo_rbs_dc$tempMax), ] # dados inv√°lidos DC
if (nrow(res) > 0) {
res[,c(1:37)] <- NA
res1 <- meteo_rbs_dc[!is.na(meteo_rbs_dc$tempMax), ] # dados v√°lidos DC
res2 <- meteo_rbs_esc[!is.na(meteo_rbs_esc$tempMax), ] |>
unique() # dados v√°lidos ESC
meteo_rbs_dc <- rbind(res1, res) |>
dplyr::arrange(timestamp) |>
unique()
## padronizando sequencia datas para preenchimento
temp <- data.frame(timestamp = seq(
from = lubridate::as_datetime(start_date),
to = lubridate::as_datetime(end_date),
by = "hour"))
meteo_rbs_dc <- dplyr::right_join(meteo_rbs_dc, temp, by = "timestamp")
res2 <- dplyr::right_join(res2, temp, by = "timestamp")
# substituindo periodo dados NA esta√ß√£o defesa civil por dados escola
meteo_rbs <- dplyr::rows_patch(meteo_rbs_dc, res2, by = "timestamp")
summary(meteo_rbs) # valores dentro do "normal"
} else{
meteo_rbs <- meteo_rbs_dc
}
#selecionando dados existentes
meteo_rbs <- meteo_rbs[!is.na(meteo_rbs$deltat), ]
# selecionando vari√°veis de interesse
meteo_rbs <- meteo_rbs |>
dplyr::mutate(Cidade = "Rio Branco do Sul",
timestamp = lubridate::force_tz(timestamp, tz = "America/Sao_Paulo")) |>
dplyr::select(Cidade, timestamp, temp, wind, direction, rain, humidity, radiation, pressure, uv)
colnames(meteo_rbs) <- c('Cidade', 'date',
'temp', 'ws', 'wd', 'prec', 'umid', 'rad', 'press', 'uv')
meteo_rbs <- rbind(meteo_rbs, last_meteo_rbs) |>
dplyr::mutate(date = lubridate::force_tz(date, tz = "America/Sao_Paulo")) |>
unique()
meteo_rbs <- rbind(meteo_rbs, last_meteo_rbs) |>
dplyr::mutate(date = lubridate::force_tz(date, tz = "America/Sao_Paulo")) |>
unique() |>
order(date)
meteo_rbs <- rbind(meteo_rbs, last_meteo_rbs) |>
dplyr::mutate(date = lubridate::force_tz(date, tz = "America/Sao_Paulo")) |>
unique() |>
dplyr::arrange(date)
# gerar arquivo
save(meteo_rbs, file = "./data/meteo/meteo_rbs.Rda")
tz(last_meteo_rbs$date)
lubridate::tz(last_meteo_rbs$date)
options("menu.graphics" = FALSE)
source("R/00-getPurpleairApiHistory.R")
purpleair_api <- Sys.getenv("PURPLEAIR_API")
#esse id pode ser obtido no mapa da PurpleAir, selecione apenas os de interesse
sensor_id <-  c('175095', '175099', '175101', '175103',
'175109', '175115', '175121', '175123',
'175235', '175393', '175395', '175387',
'175403', '175407', '175451',
'91267', '99667')
#Mais informa√ß√µes em https://api.purpleair.com/
variaveis <- c("latitude, longitude, humidity, temperature,
pm1.0_atm, pm1.0_atm_a, pm1.0_atm_b,
pm2.5_atm, pm2.5_atm_a, pm2.5_atm_b,
pm2.5_cf_1, pm2.5_cf_1_a, pm2.5_cf_1_b") # para corrigir PM2.5
todos_purpleair <- getPurpleairApiHistory(
sensorIndex    = sensor_id,
apiReadKey     = purpleair_api, #https://develop.purpleair.com/keys ### AJUSTA AQUI
startTimeStamp = Sys.time() - 86400, ### AJUSTA AQUI
endTimeStamp   = Sys.time(), ### AJUSTA AQUI
average        = "0", ### em tempo real
fields         = variaveis)
source("R/00-getPurpleairApiHistory.R")
purpleair_api <- Sys.getenv("PURPLEAIR_API")
#esse id pode ser obtido no mapa da PurpleAir, selecione apenas os de interesse
sensor_id <-  c('175095', '175099', '175101', '175103',
'175109', '175115', '175121', '175123',
'175235', '175393', '175395', '175387',
'175403', '175407', '175451',
'91267', '99667')
#Mais informa√ß√µes em https://api.purpleair.com/
variaveis <- c("latitude, longitude, humidity, temperature,
pm1.0_atm, pm1.0_atm_a, pm1.0_atm_b,
pm2.5_atm, pm2.5_atm_a, pm2.5_atm_b,
pm2.5_cf_1, pm2.5_cf_1_a, pm2.5_cf_1_b") # para corrigir PM2.5
todos_purpleair <- getPurpleairApiHistory(
sensorIndex    = sensor_id,
apiReadKey     = purpleair_api, #https://develop.purpleair.com/keys ### AJUSTA AQUI
startTimeStamp = Sys.time() - 86400, ### AJUSTA AQUI
endTimeStamp   = Sys.time(), ### AJUSTA AQUI
average        = "0", ### em tempo real
fields         = variaveis)
## or store it manually in '.Renviron':
usethis::edit_r_environ()
load("./data/data_thermo_update.Rda")
source("R/00-access-REPOnewdata-thermo-git.R")
View(data_thermo)
load("C:/Users/jessi/OneDrive/Post-Doc/Publicacoes/Git/ScheduledUpdate/data/data_thermo_update.Rda")
View(data_thermo)
data_thermo <- rbind(data_thermo, data_git)
load(file = "./data/data_thermo_update.Rda")
load("./data_raw/file_path.Rda") # data previously downloaded
View(file_path)
# Define repositories to fetch (replace with your list of repositories)
thermo_orgs <- c("Dados_GM_UFPR")  # Replace with actual repo names
github_pat <- Sys.getenv("GITHUB_PAT")
# Function to fetch the trees for each repository
get_repo_trees <- function(repo_name) {
# GitHub API endpoint to get the repository's tree
cat("Fetching tree for repo:", repo_name, "\n")
response <- gh::gh(
"GET /repos/{owner}/{repo}/git/trees/{tree_sha}",
owner = "jessicajcss",  # Replace with the owner of the repository
repo = repo_name,
tree_sha = "main",  # Replace with the tree SHA you want to retrieve, e.g., 'main' or a specific SHA
.token = github_pat,  # Use the GitHub PAT from the environment
.accept = "application/vnd.github.v3.raw",
recursive = F
)
cat("Response received for repo:", repo_name, "\n")
return(response)
}
# Iterate over all repositories and fetch the trees
thermo_repos_raw <- purrr::map(thermo_orgs, function(repo) {
tryCatch(
{
response <- get_repo_trees(repo)
cat("Successfully fetched tree for repo:", repo, "\n")
return(response)
},
error = function(e) {
cat("Error fetching tree for repo:", repo, "\n", "Error message:", e$message, "\n")
return(NULL)
}
)
})
thermo_repos <- thermo_repos_raw[[1]]$tree |>
#purrr::flatten() |>
purrr::map(unlist, recursive = TRUE)  |>
purrr::map_dfr(tibble::enframe, .id = "id_repo") |>
tidyr::pivot_wider() |>
dplyr::filter(stringr::str_detect(path,'.lsi')) |>
tidyr::separate(path, c('folder','filename'),'/')
View(thermo_repos)
load("./data_raw/file_path.Rda") # data previously downloaded
url <- thermo_repos$url
file_path_new <- url |>
as.data.frame()
View(file_path_new)
result <- thermo_repos |>
dplyr::anti_join(file_path, by = "url")
View(thermo_repos)
# PURPLEAIR IQA last 24h
load(url("https://github.com/jessicajcss/ScheduledUpdate/raw/refs/heads/main/data/data_purpleair.Rda"))
################# NOTICE: IQA last 24 h #################
# THERMO IQA last 24h
load(url("https://github.com/jessicajcss/ScheduledUpdate/raw/refs/heads/main/data/air_quality_data.Rda"))
thermo_iqa <- air_quality_data |>
dplyr::mutate(sensor = "Thermo GM-5000")
# PURPLEAIR IQA last 24h
load(url("https://github.com/jessicajcss/ScheduledUpdate/raw/refs/heads/main/data/data_purpleair.Rda"))
purpleair_iqa <- data_purpleair |>
dplyr::mutate(sensor = "PurpleAir",
AQI = AQI_PM2.5)  |>
subset(Cidade != "Rio Branco do Sul") #& Cidade != "Almirante Tamandar√©")
# unificando dados sensores
IQA_last24H <- dplyr::bind_rows(thermo_iqa, purpleair_iqa)
Cidades <- IQA_last24H$Cidade |>
unique() |>
sort()
IQA_last24H <- IQA_last24H |>
dplyr::mutate(date = lubridate::force_tz(sample_day, tz = "America/Sao_Paulo")) |>
subset(date == hoje) |>
dplyr::select(Cidade, AQI, AQI_Qualidade) |>
dplyr::group_by(Cidade) |>
dplyr::slice_max(order_by = AQI, n = 1) |> #selecionar valor m√°ximo das √∫ltimas 24h
unique()
# Selecionando dados do dia, √∫ltima hora
hoje_hora <- Sys.time() |> lubridate::force_tz("America/Sao_Paulo")
if (lubridate::hour(hoje_hora) != 0) {
# Selecionando dados do dia
hoje <- Sys.Date() |> lubridate::force_tz("America/Sao_Paulo")
} else {
hoje <- (Sys.Date() -1) |> lubridate::force_tz("America/Sao_Paulo")
}
# THERMO data in real time, in ug/m¬≥ and mg/m¬≥ (CO)
load(url("https://github.com/jessicajcss/ScheduledUpdate/raw/refs/heads/main/data/data_thermo_instantaneo_ugm3.Rda"))
lubridate::tz(data_thermo_instantaneo$date)
# PURPLEAIR data in real time, in ug/m¬≥
load(url("https://github.com/jessicajcss/ScheduledUpdate/raw/refs/heads/main/data/data_purpleair_instantaneo.Rda"))
# para valores de concentracao, prefer√™ncia √© dada ao registrado pelos GM
data_purpleair_instantaneo <- data_purpleair_instantaneo |>
dplyr::select(Cidade, date, PM2.5) |>
subset(Cidade != "Rio Branco do Sul") #& Cidade != "Almirante Tamandar√©")
data_purpleair_instantaneo$PM2.5[data_purpleair_instantaneo$PM2.5 < 0] <- 0
# unificando dados sensores
real_time <- dplyr::bind_rows(data_thermo_instantaneo, data_purpleair_instantaneo)
# selecionando ultimo registro do dia
alerta <- real_time |>
dplyr::select(-rh_sensor) |>
tidyr::pivot_longer(-c('Cidade','date'),
values_to = "concentration",
names_to = "pollutant") |>
dplyr::mutate(
limite = ifelse(pollutant == 'SO2' & concentration >= 40, 1,
ifelse(pollutant == 'NO2' & concentration >= 25, 1,
ifelse(pollutant == 'PM10' & concentration >= 45, 1,
ifelse(pollutant == 'PM2.5' & concentration >= 15, 1,
ifelse(pollutant == 'CO' & concentration >= 4, 1, 0)))))) |>
dplyr::mutate(day = as.Date(date, tz = "America/Sao_Paulo")) |>
subset(day == hoje & !is.na(concentration)) |>
dplyr::group_by(Cidade, day, pollutant) |>
dplyr::slice_max(order_by = date, n = 1) |>
unique()
################# NOTICE: IQA last 24 h #################
# THERMO IQA last 24h
load(url("https://github.com/jessicajcss/ScheduledUpdate/raw/refs/heads/main/data/air_quality_data.Rda"))
thermo_iqa <- air_quality_data |>
dplyr::mutate(sensor = "Thermo GM-5000")
# PURPLEAIR IQA last 24h
load(url("https://github.com/jessicajcss/ScheduledUpdate/raw/refs/heads/main/data/data_purpleair.Rda"))
purpleair_iqa <- data_purpleair |>
dplyr::mutate(sensor = "PurpleAir",
AQI = AQI_PM2.5)  |>
subset(Cidade != "Rio Branco do Sul") #& Cidade != "Almirante Tamandar√©")
# unificando dados sensores
IQA_last24H <- dplyr::bind_rows(thermo_iqa, purpleair_iqa)
Cidades <- IQA_last24H$Cidade |>
unique() |>
sort()
IQA_last24H <- IQA_last24H |>
dplyr::mutate(date = lubridate::force_tz(sample_day, tz = "America/Sao_Paulo")) |>
subset(date == hoje) |>
dplyr::select(Cidade, AQI, AQI_Qualidade) |>
dplyr::group_by(Cidade) |>
dplyr::slice_max(order_by = AQI, n = 1) |> #selecionar valor m√°ximo das √∫ltimas 24h
unique()
# Simulated value (replace with real data)
threshold <- 1
out <- vector("list", length(unique(alerta$pollutant))) # vetor com o correspondente numero de variaveis meteorologicas
IQA_last24H <- dplyr::filter(IQA_last24H, !is.na(Cidade))
print(dim(IQA_last24H))  # <-- Isso imprimir√° (n√∫mero de linhas, n√∫mero de colunas)
# PURPLEAIR IQA last 24h
load(file = "./data/data_purpleair.Rda")
### SOURCE DATA - MESSAGE
source('R/00-wrangled_data_whatsapp_bothThermo.R')
#####
channel_id <- Sys.getenv("WHATS_CHANNEL_ID")
whapi_token <- Sys.getenv("WHAPI_TOKEN")
#### 1¬™ Mensagem = intro
observacao <- "\n üßæ *Boletim de Qualidade do Ar \n(Lab-Air, UFPR)* \n"
#### 3¬™ Mensagem = refer√™ncia
cidades_thermo <- data_thermo_instantaneo$Cidade[data_thermo_instantaneo$date == hoje]
if ("Almirante Tamandar√©" %in% cidades_thermo & "Rio Branco do Sul" %in% cidades_thermo) {
referencia <- "\nüîé Obs.: Valores registrados por sensor da Thermo GM-5000 em Almirante Tamandar√© e Rio Branco do Sul, e sensores PurpleAir nas demais cidades. \n üßê Mais informa√ß√µes: https://rmcqualidadedoar.shinyapps.io/dados/ "
} else if ("Rio Branco do Sul" %in% cidades_thermo) {
referencia <- "\nüîé Obs.: Valores registrados por sensor da Thermo GM-5000 em Rio Branco do Sul e sensores PurpleAir nas demais cidades. \n üßê Mais informa√ß√µes: https://rmcqualidadedoar.shinyapps.io/dados/ "
} else if ("Almirante Tamandar√©" %in% cidades_thermo) {
referencia <- "\nüîé Obs.: Valores registrados por sensor da Thermo GM-5000 em Almirante Tamandar√© e sensores PurpleAir nas demais cidades. \n üßê Mais informa√ß√µes: https://rmcqualidadedoar.shinyapps.io/dados/ "
} else {
referencia <- "\nüîé Obs.: Valores registrados por sensores PurpleAir. \n üßê Mais informa√ß√µes: https://rmcqualidadedoar.shinyapps.io/dados/ "
}
out2 <- vector("list", nrow(unique(output)))
for (i in 1:nrow(output)) {
out2[[i]]$texto <- paste0("\nüìå *", output$Cidade[i],"* \n", output$qualidade[i], "\n", output$message[i], "\n")
}
output2<- dplyr::bind_rows(out2)
texto_value <- paste(output2$texto, collapse = " ")
message <- paste0(observacao,
texto_value,
referencia)
print(message) #hor√°rio 14:45 ok
# Function to send message
send_whatsapp_message <- function() {
url <- "https://gate.whapi.cloud/messages/text"
headers <- c(
'accept' = 'application/json',
'authorization' = paste0("Bearer ", whapi_token),
'content-type' = 'application/json'
)
# Message body
body <- list(
typing_time = 0,
to = paste0(channel_id, "@newsletter"),
body = message
)
# Send the request
response <- POST(url, add_headers(headers), body = body, encode = "json")
# Check the response
if (status_code(response) == 200) {
message("Message sent successfully!")
} else {
message("Failed to send message. Status code: ", status_code(response))
}
}
# Function to schedule messages
send_whatsapp_message()
### SOURCE DATA - MESSAGE
source('R/00-wrangled_data_whatsapp_bothThermo.R')
#####
channel_id <- Sys.getenv("WHATS_CHANNEL_ID")
whapi_token <- Sys.getenv("WHAPI_TOKEN")
#### 1¬™ Mensagem = intro
observacao <- "\n üßæ *Boletim de Qualidade do Ar \n(Lab-Air, UFPR)* \n"
#### 3¬™ Mensagem = refer√™ncia
cidades_thermo <- data_thermo_instantaneo$Cidade[data_thermo_instantaneo$date == hoje]
if ("Almirante Tamandar√©" %in% cidades_thermo & "Rio Branco do Sul" %in% cidades_thermo) {
referencia <- "\nüîé Obs.: Valores registrados por sensor da Thermo GM-5000 em Almirante Tamandar√© e Rio Branco do Sul, e sensores PurpleAir nas demais cidades. \n üßê Mais informa√ß√µes: https://rmcqualidadedoar.shinyapps.io/dados/ "
} else if ("Rio Branco do Sul" %in% cidades_thermo) {
referencia <- "\nüîé Obs.: Valores registrados por sensor da Thermo GM-5000 em Rio Branco do Sul e sensores PurpleAir nas demais cidades. \n üßê Mais informa√ß√µes: https://rmcqualidadedoar.shinyapps.io/dados/ "
} else if ("Almirante Tamandar√©" %in% cidades_thermo) {
referencia <- "\nüîé Obs.: Valores registrados por sensor da Thermo GM-5000 em Almirante Tamandar√© e sensores PurpleAir nas demais cidades. \n üßê Mais informa√ß√µes: https://rmcqualidadedoar.shinyapps.io/dados/ "
} else {
referencia <- "\nüîé Obs.: Valores registrados por sensores PurpleAir. \n üßê Mais informa√ß√µes: https://rmcqualidadedoar.shinyapps.io/dados/ "
}
out2 <- vector("list", nrow(unique(output)))
for (i in 1:nrow(output)) {
out2[[i]]$texto <- paste0("\nüìå *", output$Cidade[i],"* \n", output$qualidade[i], "\n", output$message[i], "\n")
}
output2<- dplyr::bind_rows(out2)
texto_value <- paste(output2$texto, collapse = " ")
message <- paste0(observacao,
texto_value,
referencia)
print(message) #hor√°rio 14:45 ok
#############
# Load necessary library
library(httr)
library(lubridate)
# Function to send message
send_whatsapp_message <- function() {
url <- "https://gate.whapi.cloud/messages/text"
headers <- c(
'accept' = 'application/json',
'authorization' = paste0("Bearer ", whapi_token),
'content-type' = 'application/json'
)
# Message body
body <- list(
typing_time = 0,
to = paste0(channel_id, "@newsletter"),
body = message
)
# Send the request
response <- POST(url, add_headers(headers), body = body, encode = "json")
# Check the response
if (status_code(response) == 200) {
message("Message sent successfully!")
} else {
message("Failed to send message. Status code: ", status_code(response))
}
}
# Function to schedule messages
send_whatsapp_message()
